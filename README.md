# BDC22
Big Data Cup 22

PDF file contains final paper. 

Data comes from: https://github.com/bigdatacup/Big-Data-Cup-2021

Competition background: https://www.stathletes.com/big-data-cup/


### Introduction
Currently, there are a lot of advanced analytics focusing on [shot quality, defending shots,](https://drive4five.blog/2021/01/06/hockey-advanced-statistics-stats-nhl-sports-analytics-aidan-resnick/) and play during even strength. This year’s Big Data Cup focuses on play during penalties as a way to gain more insights into various “special teams” strategies. During the Tracking Data Panel at the 2022 Ottawa Hockey Analytics Conference (OTTHAC), measuring defensive performance was posed as the current area of tracking analytics that had the biggest opportunity to add more depth to. Shawn Ferris echoed this sentiment in a 2020 hockey-graphs article where he said, [“there is still much more to learn about shorthanded defense with respect to understanding optimal in-zone formations and evaluating individual players”.](https://hockey-graphs.com/2020/04/16/using-data-to-inform-shorthanded-neutral-zone-decisions/#more-24218) This paper aims to build on that narrative by using 2022 Women’s Olympic Hockey event & tracking data to model around successful defensive plays as a way to scout team and individual defensive performance during penalty plays. A successful defensive play is based on a (1) Takeaway, (2) Unsuccessful Pass, (3), Dump In/Out resulting in change of possession, (4) Blocked Shot attempt, (5) Unsuccessful Zone Entry, or (6) Puck Recovery resulting in change of possession.

Current event metrics assign defensive play credit for takeaways, puck recoveries and blocked shots but these events don’t account for a majority of events such as passing, zone entry and dump in/out plays. To do so, we rely on tracking movement data to identify the closest opposing player to an offensive player as a way to give credit to a defender for the outcome of the play. The assumption we are using is that the closest defender or the one most prominent in the frame is the one most likely to be contributing to the outcome of a play. Each offensive player is assigned a closest defensive player so it is possible for a defender to be guarding multiple players for a given event. By merging the event data to the approximate time frame of the tracking data, we can gain valuable insight into the average location and separation at start, leading up to, during the event, and after the event. 

### Modelling Approach
Using a similar approach to [Jonathan Judge from Baseball Prospectus,](https://www.baseballprospectus.com/news/article/38289/bayesian-bagging-generate-uncertainty-intervals-catcher-framing-story/) a Generalized Linear Mixed Effects Model using Monte Carlo Markov Chains (MCMC) was created to identify, which defensive player had the greatest effect in adjusting the outcome of a defensive play. Our MCMC uses 5 chains and 10,000 iterations per chain to simulate and get an effective total sample size. The modeled dataset contains 1,968 different defensive play matchups (offensive player matched up to closest defensive player) for 507 unique events. In the mixed effects model, we fit the closest defensive player (for each 1,968 matchups) as the random effect. Through our exploratory analysis, we found that the following features (centered and scaled) determined a successful defensive play: **Separation** (Avg. offensive player separation or distance to any player on the ice during an event), **Net Separation** (Avg. offensive player separation to the net during an event), **Closest Opposition Player Separation** (Avg. offensive player separation to the closest defender during an event), **Closest Teammate Player Separation** (Avg. offensive player separation to closest teammate during an event), **Absolute x-Distance to Passer/Shooter** (Avg. distance of an offensive player to the passer or shooter), **Absolute x-Distance to Event Recipient** (Avg. distance of an offensive player to the recipient of the event).

#### Model Results & Evaluation
In viewing the model results, there is evidence (τ00) to show that wide variability (0.78) exists in a defender’s ability to alter a play’s outcome outside of the base model. This framework can help to identify those players who should be on ice to defend against power plays. Outside of an individual defender’s skill, the base model shows that an offensive players’ spacing and separation from each player tends to determine the outcome of a successful play. This tells us that the defender’s main goal is to reduce offensive player’s separation from anyone on the ice. Another observation is a fairly high Monte Carlo standard error of the variables in the model (typically want less than 5%) and this is likely derived from different event types included in the modeled data.![image](https://user-images.githubusercontent.com/20390351/167527869-518b49e3-2ccb-4d5c-8e9c-7748e1625d1b.png)

For evaluating the model, we used posterior predictive checking, which takes draws from the MCMC and compares the Yrep (expected defended plays in the replicated simulations) to Y (actual defended play results). As a result, we saw that the MCMC observed the binomial distribution of the output (successfully defended play or not). Using the used [Gelman and Rubin’s scale reduction factor](https://mc-stan.org/docs/2_18/reference-manual/notation-for-samples-chains-and-draws.html) or Rhat, we saw the MCMC reached proper convergence towards the target distribution with each variable and intercept’s Rhat less than 1.05. We can conclude the Bayesian MCMC model can be a good tool to evaluate defensive play during power plays. 
In determining player performance relative to the average, we created a “without defender” metric, which show the probabilistic outcome of the play (not accounting for a specific defender’s involvement). The average difference between the MCMC mean and “without defender” metric helps to create our **Defending Plays Above Average (DPAA) metric**. *DPAA* shows the lift in probability a defensive player has on the outcome of a play. Any play with a *DPAA* greater than 0 can be defined as a positively defended play.  

As a result, the model tends to identify Dump In/Outs as the event that has the highest probability of a positively defended event (e.g., Dump In/Outs resulting in a turnover). Takeaways and Puck Recoveries tend to be less positively defended which may be due to a secondary defender’s ability to disrupt a play. Passes are one of the most difficult plays to defend. Given this information, we can also use the DPAA metric specifically for passing plays as a way to identify those defenders who were especially effective in disrupting offensive movement during a power play. Given the power play situation, we can see that there are more passes than zone entries, which may be the vastly different in even strength situations.  Shawn Ferris said that “We know that deploying better offensive players, controlling more entries, and passing after those entries all lead to more shorthanded goals over time.” Players with a reputation of defending the zone line (“blue line”) and disrupting passing are more likely to be on the ice during shorthanded defensive play. DPAA can also help to highlight how proper defensive formations can reduce the performance of passing in the offensive zone.![image](https://user-images.githubusercontent.com/20390351/167528005-1f7d2f34-33dd-4736-9251-f7143d25032f.png)







